My program fulfills all of the project requirements. First, it accepts 0 to n command line arguments. If it recieves 0 arguments it will either read from the file designated by the WORD_FREAK environment variable or the standard input â€” otherwise, it will read from the files specified via the command line arguments. It also has been compiled using the included Makefile.

Upon opening the given files, the corresponding file descriptors are used (or 0 if reading from stdin) to analyze the files for words, which contain only alphabetic characters and are delimited by everything else. To do this, large chunks of the file are read all at once into a sizeable character buffer, from which bytes are collected one by one to string together words. Each separate word is placed into a word tree, which follows the structure of a binary search tree, with each node containing a word, its frequency (count), and pointers to the left and right children of the current node. The read buffer is continuously read from and reset until the end of a file is reached, after which the next file is read from if available. During this process, local variables keep track of the longest word length and number of digits of the words and their counts, respectively.

Once all given files have been read from, the contents of the word tree are output by placing each word and string-converted count into fixed-size buffers, which are then written to stdout separated by a colon, using the maximum word length and number of digits as references for the sizes of their resprctive buffers.

Demo: https://youtu.be/TrKxQoQK2As